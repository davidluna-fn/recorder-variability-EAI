{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones de la biblioteca estándar\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import sqlite3\n",
    "\n",
    "# Importaciones de terceros\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from scipy.signal import butter, sosfilt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Importaciones de módulos específicos del proyecto\n",
    "from maad import sound, features\n",
    "import indices as indices\n",
    "\n",
    "# Añadir el directorio utils al PATH para importar otros módulos si es necesario\n",
    "sys.path.append(\"../utils/\")\n",
    "\n",
    "# Configuración de la conexión a la base de datos\n",
    "conn = sqlite3.connect('../results/results.db')\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandstop_filter(audio_signal, frequencies_start, frequencies_end, fs, order=4):\n",
    "    \"\"\"\n",
    "    Apply a series of higher-order Butterworth bandstop filters to an audio signal.\n",
    "\n",
    "    Parameters:\n",
    "    - audio_signal: Numpy array containing the audio signal to be filtered.\n",
    "    - frequencies_start: List of start frequencies for the bandstop filters.\n",
    "    - frequencies_end: List of end frequencies for the bandstop filters.\n",
    "    - fs: Sampling frequency of the audio signal.\n",
    "    - order: Order of the Butterworth filters.\n",
    "\n",
    "    Returns:\n",
    "    - audio_signal: The filtered audio signal.\n",
    "    \"\"\"\n",
    "    # Ensure the frequency lists are of the same length\n",
    "    if len(frequencies_start) != len(frequencies_end):\n",
    "        raise ValueError(\"Start and end frequency lists must have the same length.\")\n",
    "\n",
    "    # Design and apply each bandstop filter\n",
    "    for start_freq, end_freq in zip(frequencies_start, frequencies_end):\n",
    "        # Calculate the Nyquist frequency\n",
    "        nyq = fs / 2.0\n",
    "        # Calculate low and high cutoff frequencies for the bandstop filter\n",
    "        low = start_freq / nyq\n",
    "        high = end_freq / nyq\n",
    "        # Design the Butterworth bandstop filter\n",
    "        sos = butter(order, [low, high], btype='bandstop', fs=fs, output='sos')\n",
    "        # Apply the filter to the audio signal\n",
    "        audio_signal = sosfilt(sos, audio_signal)\n",
    "\n",
    "    return audio_signal\n",
    "\n",
    "def get_audio_indices(file_name, apply_filter=False, start_freqs=None, end_freqs=None):\n",
    "    \"\"\"\n",
    "    Load an audio file, optionally apply a bandstop filter, and calculate various acoustic indices.\n",
    "\n",
    "    Parameters:\n",
    "    - file_name: string, path to the audio file.\n",
    "    - apply_filter: boolean, indicates if a bandstop filter should be applied.\n",
    "    - start_freqs: list of floats, start frequencies for the bandstop filters, used if apply_filter is True.\n",
    "    - end_freqs: list of floats, end frequencies for the bandstop filters, used if apply_filter is True.\n",
    "\n",
    "    Returns:\n",
    "    - indices: list, containing the file name and computed acoustic indices or np.nan in case of an error.\n",
    "    \"\"\"\n",
    "\n",
    "        # Load the audio file and compute the spectrogram\n",
    "    s, fs = torchaudio.load(str(file_name))\n",
    "    if s.size()[0] != 1:\n",
    "        s = torch.unsqueeze(s[0, :], 0)\n",
    "\n",
    "        # If filtering is applied, filter the signal before computing the spectrogram\n",
    "    if apply_filter and start_freqs is not None and end_freqs is not None:\n",
    "        s_filtered = butter_bandstop_filter(s.numpy()[0, :], start_freqs, end_freqs, fs)\n",
    "        s = torch.tensor(s_filtered.copy()[None, :])  # Add a new axis to make it 2D again\n",
    "        rms = np.sqrt(np.mean(np.square(s.numpy()[0, :])))\n",
    "        s = s / rms # Normalize the signal\n",
    "\n",
    "        # Compute the spectrogram\n",
    "    Sxx, tn, fn, ext = sound.spectrogram(s[0, :], fs, mode='amplitude')\n",
    "    Sxx_power, _, _, _ = sound.spectrogram(s[0, :], fs)\n",
    "\n",
    "        # Calculate acoustic indices\n",
    "    ACIft_ = indices.ACIft(Sxx)\n",
    "    ADI = features.acoustic_diversity_index(Sxx, fn, fmax=int(fs/2))\n",
    "    BETA = features.bioacoustics_index(Sxx, fn, flim=(2000, 8000))\n",
    "    M = features.temporal_median(s[0, :], mode='hilbert')\n",
    "    NP = features.number_of_peaks(Sxx_power, fn, slopes=6, min_freq_dist=100, display=False)\n",
    "    Hf, _ = features.frequency_entropy(Sxx_power)\n",
    "    Ht = features.temporal_entropy(s.numpy()[0, :], mode='hilbert')\n",
    "    H = Ht * Hf\n",
    "    AEI = features.acoustic_eveness_index(Sxx, fn, fmax=int(fs/2))\n",
    "    NDSI, _, _, _ = features.soundscape_index(Sxx_power, fn, flim_bioPh=(2000, 8000), flim_antroPh=(0, 2000))\n",
    "\n",
    "        # Compile all indices into a list\n",
    "    acoustic_indices = [ACIft_, ADI, BETA, M, NP, H, AEI, NDSI]\n",
    "\n",
    "        # Include file name information in the indices list\n",
    "    file_info = [str(file_name).split('/')[-1], str(file_name).split('/')[-2]]\n",
    "    return file_info + acoustic_indices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89405227d9c48229c057cffcdbef882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_folders = ['SM04', 'G0059','G0096','G0001']\n",
    "\n",
    "for x, xfolder in tqdm(enumerate(unique_folders), total=len(unique_folders)):\n",
    "    for y, yfolder in enumerate(unique_folders[x+1:]):\n",
    "        max_attempts = 5\n",
    "        attempt_delay = 2  # Tiempo de espera inicial en segundos\n",
    "\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                cfr_query = f\"SELECT * FROM comparable_frequency_range WHERE folder_x = ? AND folder_y = ?\"\n",
    "                cfr = pd.read_sql_query(cfr_query, conn, params=(xfolder, yfolder))\n",
    "                if cfr.empty:\n",
    "                    cfr = pd.read_sql_query(cfr_query, conn, params=(yfolder, xfolder))\n",
    "                    xfolder, yfolder = yfolder, xfolder\n",
    "                \n",
    "                # Deserializar las frecuencias\n",
    "                cfr['start_freq'] = cfr['start_freq'].apply(pickle.loads)\n",
    "                cfr['end_freq'] = cfr['end_freq'].apply(pickle.loads)\n",
    "                \n",
    "                # Get the indices for each file\n",
    "                xaudios = pd.read_sql_query(\"SELECT path FROM audios WHERE folder = ?\", conn, params=(xfolder,))\n",
    "                yaudios = pd.read_sql_query(\"SELECT path FROM audios WHERE folder = ?\", conn, params=(yfolder,))\n",
    "\n",
    "                for xpath, ypath in zip(xaudios.path, yaudios.path):\n",
    "                    # Suponemos que la función get_audio_indices está definida en otro lugar del código\n",
    "                    rxind = get_audio_indices(xpath)\n",
    "                    pxind = get_audio_indices(xpath, apply_filter=True, start_freqs=cfr.start_freq.iloc[0], end_freqs=cfr.end_freq.iloc[0])\n",
    "                    ryind = get_audio_indices(ypath)\n",
    "                    pyind = get_audio_indices(ypath, apply_filter=True, start_freqs=cfr.start_freq.iloc[0], end_freqs=cfr.end_freq.iloc[0])\n",
    "\n",
    "                    insert_query = \"INSERT INTO acoustic_indices (folder_x, folder_y, rx_indices, px_indices, ry_indices, py_indices) VALUES (?, ?, ?, ?, ?, ?)\"\n",
    "                    cursor.execute(insert_query, (xfolder, yfolder, pickle.dumps(rxind), pickle.dumps(pxind), pickle.dumps(ryind), pickle.dumps(pyind)))\n",
    "                    conn.commit()\n",
    "    \n",
    "                # Si llegamos aquí sin excepciones, rompemos el bucle de intentos\n",
    "                break\n",
    "\n",
    "            except sqlite3.OperationalError as e:\n",
    "                # Si es el último intento, levanta la excepción\n",
    "                if attempt == max_attempts - 1:\n",
    "                    raise\n",
    "                print(f\"OperationalError encountered on attempt {attempt+1}: {e}\")\n",
    "                print(f\"Waiting for {attempt_delay} seconds before retrying...\")\n",
    "                time.sleep(attempt_delay)\n",
    "                attempt_delay *= 2  # Incrementar el tiempo de espera para el próximo intento\n",
    "\n",
    "conn.close()\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecosap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
